<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://circuitlover.com/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://circuitlover.com/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://circuitlover.com/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://circuitlover.com/main.a2b93b20180751c6744c24b194e860074622fcaaef9ea863c11e134d4dd2a85d3218e61e63d676e9fec30269bfc4d13c4a974c02e817dc621bb00e87d3cd53ba.css integrity="sha512-ork7IBgHUcZ0TCSxlOhgB0Yi/KrvnqhjwR4TTU3SqF0yGOYeY9Z26f7DAmm/xNE8SpdMAugX3GIbsA6H081Tug==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>OpenCV C++ getting started - CircuitLover</title><meta name=description content="OpenCV getting started"><link rel=canonical href=https://circuitlover.com/blog/opencv-c-getting-started/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="OpenCV C++ getting started"><meta property="og:description" content="OpenCV getting started"><meta property="og:url" content="https://circuitlover.com/blog/opencv-c-getting-started/"><meta property="og:site_name" content="CircuitLover"><meta property="article:published_time" content="2021-03-25T00:00:00+00:00"><meta property="article:modified_time" content="2022-11-16T20:23:15+01:00"><meta property="og:image" content="https://circuitlover.com/doks.png"><meta property="og:image:alt" content="CircuitLover"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@tuyen_ld"><meta name=twitter:creator content="@tuyen_ld"><meta name=twitter:title content="OpenCV C++ getting started"><meta name=twitter:description content="OpenCV getting started"><meta name=twitter:image content="https://circuitlover.com/doks.png"><meta name=twitter:image:alt content="OpenCV C++ getting started"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://circuitlover.com/#/schema/organization/1","name":"CircuitLover","url":"https://circuitlover.com/","sameAs":["https://twitter.com/tuyen_ld","https://github.com/h-enk/doks"],"logo":{"@type":"ImageObject","@id":"https://circuitlover.com/#/schema/image/1","url":"https://circuitlover.com/logo-doks.png","width":512,"height":512,"caption":"CircuitLover"},"image":{"@id":"https://circuitlover.com/#/schema/image/1"}},{"@type":"WebSite","@id":"https://circuitlover.com/#/schema/website/1","url":"https://circuitlover.com/","name":"CircuitLover","description":"Power Electronics, embedded systems and more.","publisher":{"@id":"https://circuitlover.com/#/schema/organization/1"}},{"@type":"WebPage","@id":"https://circuitlover.com/blog/opencv-c-getting-started/","url":"https://circuitlover.com/blog/opencv-c-getting-started/","name":"OpenCV C\u002b\u002b getting started","description":"OpenCV getting started","isPartOf":{"@id":"https://circuitlover.com/#/schema/website/1"},"about":{"@id":"https://circuitlover.com/#/schema/organization/1"},"datePublished":"2021-03-25T00:00:00CET","dateModified":"2022-11-16T20:23:15CET","breadcrumb":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://circuitlover.com/blog/opencv-c-getting-started/"]}]},{"@type":"BreadcrumbList","@id":"https://circuitlover.com/blog/opencv-c-getting-started/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://circuitlover.com/","url":"https://circuitlover.com/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://circuitlover.com/blog/","url":"https://circuitlover.com/blog/","name":"Blog"}},{"@type":"ListItem","position":3,"item":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://circuitlover.com/#/schema/article/1","headline":"OpenCV C\u002b\u002b getting started","description":"OpenCV getting started","isPartOf":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/"},"mainEntityOfPage":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/"},"datePublished":"2021-03-25T00:00:00CET","dateModified":"2022-11-16T20:23:15CET","author":{"@id":"https://circuitlover.com/#/schema/person/2"},"publisher":{"@id":"https://circuitlover.com/#/schema/organization/1"},"image":{"@id":"https://circuitlover.com/blog/opencv-c-getting-started/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://circuitlover.com/#/schema/person/2","name":"Tuyen D. Le","sameAs":["https://twitter.com/tuyen_ld","https://www.linkedin.com/in/ledinhtuyen/","https://github.com/tuyenld"]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://circuitlover.com/blog/opencv-c-getting-started/#/schema/image/2","url":"https://circuitlover.com/doks.png","contentUrl":"https://circuitlover.com/doks.png","caption":"OpenCV C\u002b\u002b getting started"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://circuitlover.com/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://circuitlover.com/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://circuitlover.com/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://circuitlover.com/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://circuitlover.com/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://circuitlover.com/site.webmanifest></head><body class="blog single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/ aria-label=CircuitLover>CircuitLover</a>
<button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>CircuitLover</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/blog/>Blog</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search ..." aria-label="Search ..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/tuyenld><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://twitter.com/tuyen_ld><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-lg-none">Twitter</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class="wrap container-xxl" role=document><div class=content><article><div class="row justify-content-center"><div class="col-md-12 col-lg-10"><div class=blog-header><h1>OpenCV C++ getting started</h1><p><small>Posted&nbsp;in&nbsp;<a class="stretched-link position-relative link-muted" href=https://circuitlover.com/categories/open-cv/>Open-CV</a>&nbsp;on&nbsp;March 25, 2021 by <a class="stretched-link position-relative" href=/contributors/tuyen-d.-le/>Tuyen D. Le</a>&nbsp;&dash;&nbsp;<strong>6&nbsp;min read</strong></small><p></div></div><div class=col-md-13><div></div></div><div class="col-md-12 col-lg-9"><p>Table of Contents</p><ul><li><a href=#install>Install</a><ul><li><a href=#download>Download</a></li><li><a href=#configure>Configure</a><ul><li><a href=#histogram-equalization-he>Histogram equalization (HE)</a></li></ul></li><li><a href=#learning-opencv-3-computer-vision-in-c-with-the-opencv-library-adrian-kaehler-and-gary-bradski>Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski)</a></li><li><a href=#code>Code</a></li><li><a href=#distancetransform>distanceTransform</a></li><li><a href=#type>Type</a></li><li><a href=#scalar>Scalar</a></li><li><a href=#differences-of-using-const-cvmat--cvmat--cvmat-or-const-cvmat-as-function-parameters>Differences of using “const cv::Mat &”, “cv::Mat &”, “cv::Mat” or “const cv::Mat” as function parameters?</a></li><li><a href=#linear-vs-non-linear-filter>Linear vs non-linear filter</a></li><li><a href=#but-what-is-the-fourier-transform-a-visual-introduction>But what is the Fourier Transform? A visual introduction</a></li><li><a href=#clahe>CLAHE</a></li><li><a href=#laplacianlaplacian-of-gaussian>Laplacian/Laplacian of Gaussian</a></li><li><a href=#wavelet>Wavelet</a></li><li><a href=#mean-vs-median-filter>Mean vs Median filter</a></li><li><a href=#point2f-sub-pixel-coordinate-origin>Point2f, sub-pixel coordinate origin</a></li><li><a href=#understanding-and-evaluating-template-matching-methods>Understanding and evaluating template matching methods</a></li><li><a href=#understanding-moments-function-in-opencv>Understanding Moments function in opencv</a></li></ul></li><li><a href=#clone-all-fiji-source-code>Clone all Fiji source code</a></li><li><a href=#findcontours>findContours()</a></li></ul><h2 id=install>Install <a href=#install class=anchor aria-hidden=true>#</a></h2><h3 id=download>Download <a href=#download class=anchor aria-hidden=true>#</a></h3><ul><li>Microsoft Visual C++ 2019 <a href=https://download.visualstudio.microsoft.com/download/pr/3a7354bc-d2e4-430f-92d0-9abd031b5ee5/d9fc228ea71a98adc7bc5f5d8e8800684c647e955601ed721fcb29f74ace7536/vs_Community.exe>Community</a></li><li><a href=https://nchc.dl.sourceforge.net/project/opencvlibrary/4.5.1/opencv-4.5.1-vc14_vc15.exe>opencv_4.5.1</a></li><li><a href=https://nchc.dl.sourceforge.net/project/opencvlibrary/3.4.13/opencv-3.4.13-vc14_vc15.exe>opencv_3.4.13</a></li></ul><h3 id=configure>Configure <a href=#configure class=anchor aria-hidden=true>#</a></h3><p>https://acodary.wordpress.com/2018/07/24/opencv-cai-dat-opencv-visual-c-tren-windows/</p><ul><li>Project > Property<ul><li>Platform: x64</li><li>Configuration Properties<ul><li>C/C++ > General: opencv\build\include</li><li>Linker > General: opencv\build\x64\vc15\lib</li><li>Linker > Input:<ul><li>For openCV_4.5.1: <code>opencv_world451d.lib</code> OR <code>opencv_world451.lib</code> (d for debug)</li><li>For opencv_3.4.13: <code>opencv_world3413d.lib</code></li></ul></li></ul></li></ul></li><li>Add <code>D:\tuyenld\dev\opencv_3.4.13\build\x64\vc15\bin</code> (remember to correct your path) to PATH environment</li></ul><h4 id=histogram-equalization-he>Histogram equalization (HE) <a href=#histogram-equalization-he class=anchor aria-hidden=true>#</a></h4><ul><li>Đây chỉ là một phương pháp, có thể cho kết quả không phải flat toàn spectrum</li><li>Nếu histogram một bài toán thay đổi liên tục thì phải dùng HE (tự động). Các trường hợp khác thì có thể fixed histogram và không cần dùng đến HE00</li></ul><h3 id=learning-opencv-3-computer-vision-in-c-with-the-opencv-library-adrian-kaehler-and-gary-bradski>Learning OpenCV 3 Computer Vision in C++ with the OpenCV Library (Adrian Kaehler and Gary Bradski) <a href=#learning-opencv-3-computer-vision-in-c-with-the-opencv-library-adrian-kaehler-and-gary-bradski class=anchor aria-hidden=true>#</a></h3><p>https://github.com/oreillymedia/Learning-OpenCV-3_examples</p><h3 id=code>Code <a href=#code class=anchor aria-hidden=true>#</a></h3><ul><li><a href=https://docs.opencv.org/3.4.13>Online</a></li></ul><h3 id=distancetransform>distanceTransform <a href=#distancetransform class=anchor aria-hidden=true>#</a></h3><p><a href=https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm>Ref1</a></p><ul><li>takes <strong>binary images</strong> as inputs.</li><li>the <strong>gray level intensities</strong> of the points inside the foreground regions are changed to distance their respective distances from the closest 0 value (boundary)</li></ul><h3 id=type>Type <a href=#type class=anchor aria-hidden=true>#</a></h3><ul><li><a href=http://ninghang.blogspot.com/2012/11/list-of-mat-type-in-opencv.html>Ref1</a></li><li><a href=https://stackoverflow.com/questions/8377091/what-are-the-differences-between-cv-8u-and-cv-32f-and-what-should-i-worry-about/8377146>Ref2</a></li></ul><p>A Mapping of Type to Numbers in OpenCV</p><table><thead><tr><th></th><th>C1</th><th>C2</th><th>C3</th><th>C4</th><th>Type</th><th>Bits</th><th>C++ type</th><th>Range</th></tr></thead><tbody><tr><td>CV_8U</td><td>0</td><td>8</td><td>16</td><td>24</td><td>Unsigned</td><td>8bits</td><td>uchar</td><td>0~255</td></tr><tr><td>CV_8S</td><td>1</td><td>9</td><td>17</td><td>25</td><td>Signed</td><td>8bits</td><td>char</td><td>-128~127</td></tr><tr><td>CV_16U</td><td>2</td><td>10</td><td>18</td><td>26</td><td>Unsigned</td><td>16bits</td><td>ushort</td><td>0~65.535</td></tr><tr><td>CV_16S</td><td>3</td><td>11</td><td>19</td><td>27</td><td>Signed</td><td>16bits</td><td>short</td><td>-32.768~32.767</td></tr><tr><td>CV_32S</td><td>4</td><td>12</td><td>20</td><td>28</td><td>Signed</td><td>32bits</td><td>int</td><td>-2.147.483.648~2.147.483.647</td></tr><tr><td>CV_32F</td><td>5</td><td>13</td><td>21</td><td>29</td><td>Float</td><td>32bits</td><td>float</td><td><strong>0~1.0</strong></td></tr><tr><td>CV_64F</td><td>6</td><td>14</td><td>22</td><td>30</td><td>Double</td><td>64bits</td><td>double</td><td></td></tr></tbody></table><pre><code class=language-cpp>#define CV_8U   0
#define CV_8S   1 
#define CV_16U  2
#define CV_16S  3
#define CV_32S  4
#define CV_32F  5
#define CV_64F  6

#define CV_8UC1 CV_MAKETYPE(CV_8U,1)
#define CV_8UC2 CV_MAKETYPE(CV_8U,2)
#define CV_8UC3 CV_MAKETYPE(CV_8U,3)
#define CV_8UC4 CV_MAKETYPE(CV_8U,4)
#define CV_8UC(n) CV_MAKETYPE(CV_8U,(n))

#define CV_CN_SHIFT   3
#define CV_DEPTH_MAX  (1 &lt;&lt; CV_CN_SHIFT)

#define CV_MAT_DEPTH_MASK       (CV_DEPTH_MAX - 1)
#define CV_MAT_DEPTH(flags)     ((flags) &amp; CV_MAT_DEPTH_MASK)

#define CV_MAKETYPE(depth,cn) (CV_MAT_DEPTH(depth) + (((cn)-1) &lt;&lt; CV_CN_SHIFT))

// For example: 
#define CV_8UC4 CV_MAKETYPE(CV_8U,4)
// has type: 0+((4-1) &lt;&lt; 3) == 24
</code></pre><ul><li>1 is the default number of channels (<code>CV_8U = CV_8UC1 = 0</code>)</li><li>CV_32F defines the depth of each element of the matrix</li><li>CV_32FC1 defines both the depth of each element and the number of channels.</li></ul><h3 id=scalar>Scalar <a href=#scalar class=anchor aria-hidden=true>#</a></h3><p>Template class for a 4-element vector derived from Vec.
Being derived from <code>Vec&lt;Tp, 4></code>
Scalar can be used just as typical 4-element vectors.
The type Scalar is widely used in OpenCV to pass pixel values.</p><pre><code class=language-cpp>cv::Scalar myWhite(255, 255, 500);
cout &lt;&lt; &quot;Scala0: &quot; &lt;&lt; myWhite[0] &lt;&lt; &quot;; Scala1: &quot; 
     &lt;&lt; myWhite[1] &lt;&lt; &quot;; Scala2: &quot; &lt;&lt; myWhite[2] &lt;&lt; endl;

// Scala0: 255; Scala1: 255; Scala2: 500
</code></pre><h3 id=differences-of-using-const-cvmat--cvmat--cvmat-or-const-cvmat-as-function-parameters>Differences of using “const cv::Mat &”, “cv::Mat &”, “cv::Mat” or “const cv::Mat” as function parameters? <a href=#differences-of-using-const-cvmat--cvmat--cvmat-or-const-cvmat-as-function-parameters class=anchor aria-hidden=true>#</a></h3><p>https://stackoverflow.com/a/23486280</p><blockquote><p>OpenCV handles all the memory <a href=https://docs.opencv.org/2.4/modules/core/doc/intro.html#automatic-memory-management>automatically</a>.
First of all, std::vector, Mat, and other data structures used by the functions and methods have destructors that deallocate the underlying memory buffers when needed. This means that the destructors do not always deallocate the buffers as in case of Mat. They take into account possible data sharing. A destructor decrements the reference counter associated with the matrix data buffer. The buffer is deallocated if and only if the reference counter reaches zero, that is, when no other structures refer to the same buffer. Similarly, when a Mat instance is copied, no actual data is really copied. Instead, the reference counter is incremented to memorize that there is another owner of the same data. There is also the Mat::clone method that creates a full copy of the matrix data.</p></blockquote><h3 id=linear-vs-non-linear-filter>Linear vs non-linear filter <a href=#linear-vs-non-linear-filter class=anchor aria-hidden=true>#</a></h3><p><a href=https://www.embeddedcomputing.com/technology/analog-and-power/comparing-linear-versus-nonlinear-filters-in-image-processing>Ref</a></p><ul><li>In cases where the input data contains a large amount of noise but the magnitude is low, a linear low-pass filter may suffice.</li><li>Conversely, if an image contains a low amount of noise but with relatively high magnitude, then a median filter may be more appropriate.</li><li>In either case, the filter process changes the overall frequency content of the image.</li></ul><h3 id=but-what-is-the-fourier-transform-a-visual-introduction>But what is the Fourier Transform? A visual introduction <a href=#but-what-is-the-fourier-transform-a-visual-introduction class=anchor aria-hidden=true>#</a></h3><p>https://youtu.be/spUNpyF58BY</p><ul><li>Fourier Series > Periodic function of a continuous variable</li><li>Fourier Transform > Not periodic function</li></ul><h3 id=clahe>CLAHE <a href=#clahe class=anchor aria-hidden=true>#</a></h3><ul><li><a href=https://web.archive.org/web/20120113220509/http://radonc.ucsf.edu/research_group/jpouliot/tutorial/HU/Lesson7.htm>Contrast Limited Adaptative Histogram Equalization (CLAHE)</a></li><li><a href=https://github.com/erich666/GraphicsGems/blob/master/gemsiv/clahe.c>clahe.c</a></li><li><a href=http://cas.xav.free.fr/Graphics%20Gems%204%20-%20Paul%20S.%20Heckbert.pdf>Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV p482/579</a></li></ul><blockquote><p>Division of the image into 8x8 contextual regions usually gives good results; this implies 64 contextual regions of size 64x64 when AHE is performed on a 512x512 image</p></blockquote><p>??</p><blockquote><p>To avoid visibility of region boundaries, a <a href=https://theailearner.com/2018/12/29/image-processing-bilinear-interpolation/>bilinear interpolation</a> scheme is used (see Fig.2)</p></blockquote><h3 id=laplacianlaplacian-of-gaussian>Laplacian/Laplacian of Gaussian <a href=#laplacianlaplacian-of-gaussian class=anchor aria-hidden=true>#</a></h3><ul><li><p>https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm</p></li><li><p>https://hcimage.com/help/Content/Quantitation/Measurements/Processing%20and%20Analysis/Enhance/Enhance%20Operations.htm</p></li><li><p>https://softwarebydefault.com/2013/05/11/image-edge-detection/</p></li><li><p><a href=https://youtu.be/Iz6C1ny-F2Q>The Two-Dimensional Discrete Fourier Transform</a></p></li><li><p><a href=https://youtu.be/YYGltoYEmKo>2-Dimensional Discrete-Space Fourier Transform</a></p></li></ul><p>edge preserving filter in image processing opencv</p><h3 id=wavelet>Wavelet <a href=#wavelet class=anchor aria-hidden=true>#</a></h3><p>http://www.nsl.hcmus.edu.vn/greenstone/collect/tiensifu/index/assoc/HASH01f6.dir/2.pdf
<a href=https://blancosilva.wordpress.com/teaching/mathematical-imaging/denoising-wavelet-thresholding/>Denoising: wavelet thresholding</a>
<a href=https://vdocuments.mx/download/ung-dung-phep-bien-doi-wavelet-trong-xu-ly-anh>Ứng dụng phép biến đổi wavelet trong xử lý ảnh PTIT</a></p><h3 id=mean-vs-median-filter>Mean vs Median filter <a href=#mean-vs-median-filter class=anchor aria-hidden=true>#</a></h3><p>The &ldquo;mean&rdquo; is the &ldquo;average&rdquo; you&rsquo;re used to, where you add up all the numbers and then divide by the number of numbers.
The &ldquo;median&rdquo; is the &ldquo;middle&rdquo; value in the list of numbers.</p><ul><li>Median filter: suitable for grayscale image, don&rsquo;t use with binary image</li></ul><h3 id=point2f-sub-pixel-coordinate-origin>Point2f, sub-pixel coordinate origin <a href=#point2f-sub-pixel-coordinate-origin class=anchor aria-hidden=true>#</a></h3><ul><li><p>References:</p><ul><li><a href=https://answers.opencv.org/question/87923/sub-pixel-coordinate-origin/>Sub-pixel coordinate origin</a></li><li><a href=https://github.com/opencv/opencv/issues/10130>Absent documentation for sub-pixel coordinate system</a></li></ul></li><li><p><strong>Conclusion</strong></p><ul><li>According to results above it seems that <code>cv2.remap</code> uses coordinate system with pixel centers aligned to their integer indexes.</li><li><code>top-left pixel center</code> coordinate is <code>(0,0)</code></li><li>top left pixel spans from (-0.5,-0.5) to (+0.5,+0.5)</li><li>whole image spans from (-0.5,-0.5) to (W-0.5, H-0.5)
<img class="img-fluid lazyload blur-up" srcset="/blog/opencv-c-getting-started/images/point2f-coordinate_hu9b1bbe747c49ec6f6dcc0f91a2de0d54_10123_38f00b8d9ed5de9330aa8779dcf668b7.webp 480w, /blog/opencv-c-getting-started/images/point2f-coordinate_hu9b1bbe747c49ec6f6dcc0f91a2de0d54_10123_675x0_resize_q75_h2_box_3.webp 675w" sizes=80vw src=/blog/opencv-c-getting-started/images/point2f-coordinate_hu9b1bbe747c49ec6f6dcc0f91a2de0d54_10123_675x0_resize_q75_h2_box_3.webp alt="Point2f coordinate" width=675 height=580></li></ul></li></ul><h3 id=understanding-and-evaluating-template-matching-methods>Understanding and evaluating template matching methods <a href=#understanding-and-evaluating-template-matching-methods class=anchor aria-hidden=true>#</a></h3><p><a href=https://stackoverflow.com/a/58160295>alkasm&rsquo;s anwser</a></p><p>TM_SQDIFF_NORMED, TM_CCORR_NORMED, TM_CCOEFF_NORMED
TM_SQDIFF, TM_CCORR, TM_CCOEFF</p><table><thead><tr><th>TM_CCOEFF_NORMED</th><th>TM_CCORR_NORMED</th><th>TM_SQDIFF_NORMED</th></tr></thead><tbody><tr><td>[-1, 1] (mean shifted)</td><td>[0, 1]</td><td>[0, 1]</td></tr></tbody></table><h3 id=understanding-moments-function-in-opencv>Understanding Moments function in opencv <a href=#understanding-moments-function-in-opencv class=anchor aria-hidden=true>#</a></h3><p><a href=https://stackoverflow.com/a/22472044>Michael Burdinov&rsquo;s answer</a></p><p>Definition of moments in image processing is borrowed from physics. Assume that each pixel in image has weight that is equal to its intensity. Then the point you defined is centroid (a.k.a. center of mass) of image.</p><p>Assume that <code>I(x,y)</code> is the intensity of pixel <code>(x,y)</code> in image. Then <code>m(i,j)</code> is the sum for all possible x and y of: <code>I(x,y) * (x^i) * (y^j)</code>.</p><p>And <a href=https://en.wikipedia.org/wiki/Image_moment>here</a> you can read a wiki article about all kinds of image moments (raw moments, central moments, scale/rotation invariant moments and so on). It is pretty good one and I recommend reading it.</p><p>Adapting this to scalar (greyscale) image with pixel intensities I(x,y), raw image moments Mij are calculated by:</p>$$
{\displaystyle M_{ij} = \sum_{x}\sum_{y}x^{i}y^{j}I(x,y)\,\!}M_{{ij}}=\sum _{x}\sum_{y}x^{i}y^{j}I(x,y)
$$<p>Centroid: ${\displaystyle {{\bar {x}},\ {\bar {y}}}=\left{{\frac {M_{10}}{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}{\displaystyle {{\bar {x}},\ {\bar {y}}}=\left{{\frac {M_{10}}{M_{00}}},{\frac {M_{01}}{M_{00}}}\right}}$</p><h2 id=clone-all-fiji-source-code>Clone all Fiji source code <a href=#clone-all-fiji-source-code class=anchor aria-hidden=true>#</a></h2><pre><code class=language-bash># https://forum.image.sc/t/getting-the-source-code-for-fiji-without-using-maven/31964/6

sudo apt install maven
sudo apt install libxml2-utils

git clone git://github.com/fiji/fiji
cd fiji/bin
wget https://github.com/scijava/scijava-scripts/raw/master/melting-pot.sh
bin/melt.sh -s
</code></pre><h2 id=findcontours>findContours() <a href=#findcontours class=anchor aria-hidden=true>#</a></h2><p>Reference:</p><ul><li><a href=http://amroamroamro.github.io/mexopencv/opencv/contours_hierarchy_demo.html>mexopencv</a></li><li><a href=https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a>group__imgproc__shape</a></li></ul><p>Remember:</p><ul><li>In OpenCV, object to be found should be white and background should be black.</li></ul><pre><code class=language-cpp>void cv::findContours
    (   InputOutputArray    image,
        OutputArrayOfArrays contours,
        OutputArray         hierarchy,
        int                 mode,
        int                 method,
        Point               offset = Point() 
    ) 

// Note: absolute value of an area is used because
// area may be positive or negative - in accordance with the
// contour orientation
double i = std::fabs(cv::contourArea(cv::Mat(contour1)));
</code></pre><p>What is <strong>Contour Approximation Method</strong>?</p><p>CHAIN_APPROX_NONE vs CHAIN_APPROX_SIMPLE</p><p><img class="img-fluid lazyload blur-up" srcset="/blog/opencv-c-getting-started/images/findcontours-method_huc06c3d869b96e18f52b0a28e07b34721_5346_459x0_resize_q75_h2_box_3.webp 459w" sizes=80vw src=/blog/opencv-c-getting-started/images/findcontours-method_huc06c3d869b96e18f52b0a28e07b34721_5346_459x0_resize_q75_h2_box_3.webp alt=findcontours-method width=459 height=178></p><p>What is <strong>Contours Hierarchy</strong>?</p><p><img class="img-fluid lazyload blur-up" srcset="/blog/opencv-c-getting-started/images/find-contours-hierarchy_hu986cd00cc0ce973d90fc5368681030a5_5168_450x0_resize_q75_h2_box_3.webp 450w" sizes=80vw src=/blog/opencv-c-getting-started/images/find-contours-hierarchy_hu986cd00cc0ce973d90fc5368681030a5_5168_450x0_resize_q75_h2_box_3.webp alt=find-contours-hierarchy width=450 height=292></p><ul><li>Contour <strong>0,1,2</strong> are the same hierachy level</li><li><em>child</em>(2) = 2a; <em>parent</em>(2a) = 2</li></ul><div class=mt-4><a class="btn btn-light" href=https://circuitlover.com/tags/getting-started/ role=button>getting-started</a></div></div></div></article></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-12 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Content on this site is released under a <a class=text-muted href=https://creativecommons.org/licenses/by-nc/4.0/>Creative Commons BY-NC License</a> .Powered by <a class=text-muted href=https://gohugo.io/>Hugo</a> and <a class=text-muted href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-4 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script src=/js/bootstrap.min.6cdb76625316a021e696f0641e0948e88df021948825dbf90228403664b1691ff7a291ac9d485a8da13b1cc8b9d543ba6dce6702692ff979943a02038ffbd52e.js integrity="sha512-bNt2YlMWoCHmlvBkHglI6I3wIZSIJdv5AihANmSxaR/3opGsnUhajaE7HMi51UO6bc5nAmkv+XmUOgIDj/vVLg==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.438b1431b05b2411eae056496512a11db74da52f59f45cae76e0f4cd53401019b958855157713b977b67d179b9a56c28f9ba0072d4d1670dace5163ec85d03a5.js integrity="sha512-Q4sUMbBbJBHq4FZJZRKhHbdNpS9Z9FyuduD0zVNAEBm5WIVRV3E7l3tn0Xm5pWwo+boActTRZw2s5RY+yF0DpQ==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/katex.min.33bfe3919a0a1259f58da698daba022bd26de2dfa3fe2aeed1edaf2270e454ee4b634101b779baead8d34f95c5b061f62c91be55144bdae7884775347ebb3f19.js integrity="sha512-M7/jkZoKEln1jaaY2roCK9Jt4t+j/iru0e2vInDkVO5LY0EBt3m66tjTT5XFsGH2LJG+VRRL2ueIR3U0frs/GQ==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/contrib/auto-render.min.f128dc24877a8ff5cdc694570f6cd25f8ad512d4330c242487c4cbbc5dc6fd2c52de778da1e59f98585d1defd5aa5aa583da59e90e6837973ecca3b45b01fb64.js integrity="sha512-8SjcJId6j/XNxpRXD2zSX4rVEtQzDCQkh8TLvF3G/SxS3neNoeWfmFhdHe/Vqlqlg9pZ6Q5oN5c+zKO0WwH7ZA==" crossorigin=anonymous defer></script>
<script src=/main.min.0aae37ae653863c10698d1a14193ab9c3527f57b4a9746b1c51e80b8d2188193ad5b91c191036b35a58522bbe6cd50431b351c2a5f2e55f81a3d0838739587d5.js integrity="sha512-Cq43rmU4Y8EGmNGhQZOrnDUn9XtKl0axxR6AuNIYgZOtW5HBkQNrNaWFIrvmzVBDGzUcKl8uVfgaPQg4c5WH1Q==" crossorigin=anonymous defer></script>
<script src=https://circuitlover.com/index.min.6d2a391612711d63cdec4bb368aea6fdfce2b8bf8554fe74b1ee4e6cebe43e3cc00136c9a787ebabce705ce99aaede480c85028fcecfa7a2820b6c5912d24ba2.js integrity="sha512-bSo5FhJxHWPN7EuzaK6m/fziuL+FVP50se5ObOvkPjzAATbJp4frq85wXOmart5IDIUCj87Pp6KCC2xZEtJLog==" crossorigin=anonymous defer></script><div class="d-flex fixed-bottom pb-4 pb-lg-5 pe-4 pe-lg-5"><a id=toTop href=# class="btn btn-outline-primary rounded-circle ms-auto p-2"><span class=visually-hidden>Top</span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-up"><polyline points="18 15 12 9 6 15"/></svg></a></div></body></html>